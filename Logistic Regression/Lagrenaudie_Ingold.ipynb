{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colun or semicolun ?\n",
    "\n",
    "In this notebook, you are going to implement a logistic regression algrorithm.\n",
    "- 1st, you'll build a dataset\n",
    "- 2nd, you'll you are going do define a model\n",
    "- 3rd, a backpropagation method\n",
    "- 4th, a gradient descent method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Dataset\n",
    "\n",
    "We build a dataset to illustrate our purpose.\n",
    "\n",
    "The dataset we build is supposed to help us converting a paper scan into a ASCII string. Lets imagine that, when a paper is scaned, we can detect, with high confidence that we are over a colun or a semicolun. Our objective here is to detect wether it's one or the other.\n",
    "\n",
    "Therefore, our algorithm is fed with a vector $x_i \\in [0,1]^5$ which represent the intensity of the pen stroke writting on the paper.\n",
    "\n",
    "Here below, you have an example of 'perfect' strokes for $x_1$ an example of colun, and $x_2$ an example of semicolun. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVgAAAD8CAYAAAAylrwMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9EElAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20f8d318da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x_1 = np.array([0,1,0,1,0])\n",
    "x_2 = np.array([0,1,0,1,1])\n",
    "\n",
    "def to_img(vec):\n",
    "    matrix = np.ones((5, 3))\n",
    "    matrix[:, 1] = 1-vec\n",
    "    return matrix\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "axs[0].imshow(to_img(x_1), cmap='gray')\n",
    "axs[1].imshow(to_img(x_2), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever a sample $x_i$ belongs to the class *colun*, we'll label it with $y_i=0$.  \n",
    "Likewise, whenever a sample $x_i$ belongs to the class *semicolun*, we'll label it with $y_i=1$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_1 = 0\n",
    "y_2 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAByCAYAAABOU1q9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVcPobONB/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20f8dd08cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.array([\n",
    "    [.0, 1., 0., 1., 0.],\n",
    "    [.0, .9, 0., .9, 0.],\n",
    "    [.2, .8, 0., .8, .2],\n",
    "    [.0, 1., 0., 1., 1.],\n",
    "    [.0, 1., 0., .5, .5],\n",
    "    [.2, .8, 0., .7, .7]])\n",
    "y = np.array([0,0,0,1,1,1])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,6)\n",
    "for i in range(len(X)):\n",
    "    axs[i].imshow(to_img(X[i]), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Define a logistic regression model\n",
    "\n",
    "(You may want to read this : http://cs229.stanford.edu/notes/cs229-notes1.pdf).\n",
    "\n",
    "You're going to build a model which outputs a prediction value $p_i$ given an input $x_i$. This prediction $p_i$ will reflect the propability that your input $x_i$ belongs to class 1.\n",
    "$$\n",
    "\\begin{align}\n",
    "p_i &= P(Y=1 | W, x_i) \\\\\n",
    "p(x_i,W) &= P(Y=1 | W, x_i)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "As $p_i$ is a probability, it must be in [0,1].\n",
    "\n",
    "The model we'll consider perform a weighted sum of its input:\n",
    "- Weighted sum : $ s = (W^t \\cdot X + b) $\n",
    "\n",
    "And then squizes the values between 0 and 1 (which is our prediction value):\n",
    "- prediction : $ p(s) = \\frac{1}{1 + e^{-s}} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.8994728   0.88817587  0.8897987   0.94439319  0.90087515  0.91278709]]\n"
     ]
    }
   ],
   "source": [
    "b=1\n",
    "W = np.random.random((1,5))\n",
    "s=np.dot(W,X.transpose())+b\n",
    "\n",
    "def sigmoid(s):\n",
    "    return 1/(1+np.exp(-s))\n",
    "              \n",
    "p=sigmoid(s)\n",
    "print (p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Compare these predicted values ($p_i$) with the true output ($y_i$)\n",
    "\n",
    "Overall, we would like to maximize the likelihood that we are right at predicting a label.  \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\max \\text{likelihood} &= \\text{argmax}_w \\Pi_i P(Y | W, x_i) \\\\\n",
    "&= \\text{argmax}_w \\Pi_i \\big( P(Y=y_i | W, x_i) \\big) \\\\\n",
    "&= \\text{argmax}_w \\Pi_i \\big( P(Y=1 | W, x_i)^{y_i} \\cdot P(Y=0 | W, x_i)^{1-y_i} \\big) \\\\\n",
    "&= \\text{argmax}_w \\Pi_i \\big( P(Y=1 | W, x_i)^{y_i} \\cdot 1-P(Y=1 | W, x_i)^{1-y_i}\\big) \\\\\n",
    "&= \\text{argmax}_w \\Pi_i \\big( p_i^{y_i} \\cdot 1-p_i^{1-y_i}\\big) \\\\\n",
    "&= \\text{argmax}_w \\sum_i \\big( y_i \\ln(p_i) + (1-y_i) \\ln(1-p_i) \\big) \\\\\n",
    "&= \\text{argmin}_w - \\sum_i \\big( y_i \\ln(p_i) + (1-y_i) \\ln(1-p_i) \\big) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "And this term is going to be our **loss** that we want to reduce:\n",
    "$$\n",
    "L(x_i, W, y_i) = - \\sum_i \\big( y_i \\ln(p_i) + (1-y_i) \\ln(1-p_i) \\big)\n",
    "$$\n",
    "This is how you compare the prediction you made ($p_i$) to the true output you expected ($y_i$).\n",
    "\n",
    "#### In our example :\n",
    "In means of colun and semicolun : remember $x_0$, it's a colun, therefore it's label is $y_0=0$.  \n",
    "If your classifier is good you'ld expect it to predict it's a semicolun, hense have $p_i = $*\"Something small like 0.1\"*. \n",
    "\n",
    "The error for this one sample is going to be:\n",
    "$$\n",
    "\\begin{align}\n",
    "L(X, W, y) &= - \\sum_i \\big( y_i \\ln(p_i) + (1-y_i) \\ln(1-p_i) \\big) \\\\\n",
    "&= y_0 \\ln(p_0) + (1-y_0) \\ln(1-p_0) \\\\\n",
    "&= - 0 \\ln(.9) + (1-0) \\ln(1-.9) \\\\\n",
    "&= - \\ln(.1)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the minimum of the Loss function\n",
    "\n",
    "To reduce the error, we have to find the minimum of $L(x, W, y)$.  \n",
    "Hense, we derive it with respect to $W$ and find the 'zeros'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02675286  0.38102801  0.          0.30740863  0.08529024]]\n"
     ]
    }
   ],
   "source": [
    "def ln(x) :\n",
    "    return np.log(x)\n",
    "\n",
    "def deriveLoss(y,W,X) :\n",
    "    s=np.dot(W,X.transpose())+b\n",
    "    p=sigmoid(s)\n",
    "    P_Y=np.zeros([1,6])  \n",
    "    for i in range(0,len(y)):\n",
    "        P_Y[0,i]=p[0,i]-y[i,]\n",
    "        derive=np.dot(P_Y,X)/len(X)\n",
    "    return derive\n",
    "print (deriveLoss(y,W,X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Stochastic gradient descent to solve this\n",
    "\n",
    "We are going to solve this with Stochastic Gradient Descent (SGD), meaning that we start with some values for $W$ and update this values such that our loss value disminushes.\n",
    "$$\n",
    "W = W + \\alpha \\frac{\\delta L(x, W, y)}{\\delta W}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y we want :\n",
      "[0 0 0 1 1 1]\n",
      "prediction\n",
      "[[ 0.00578594  0.01064598  0.15188978  0.99947709  0.84764228  0.99128139]]\n",
      "weights\n",
      "[[ -1.71529812  -5.12313195   0.65280342  -1.0233901   12.7021091 ]]\n"
     ]
    }
   ],
   "source": [
    "alpha=0.01\n",
    "print (\"y we want :\" )\n",
    "print (y)\n",
    "for i in range (1,20000) :\n",
    "    W=W-alpha*deriveLoss(y,W,X)\n",
    "print(\"prediction\")\n",
    "print(sigmoid(np.dot(W,X.transpose())+b))\n",
    "print(\"weights\")\n",
    "print (W)\n",
    "    \n",
    "        \n",
    "   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
